{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 Computer Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch as tc\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Getting our datsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Please do not run the code below more than once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"DATA\", train=True, download=True, transform=ToTensor(), target_transform=None\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"DATA\", train=False, download=True, transform=ToTensor(), target_transform=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Please do not run the code above more than once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data\n",
    "# seeing the first data\n",
    "image,label = train_data[0]\n",
    "image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classnames = train_data.classes\n",
    "classnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_idx = train_data.class_to_idx\n",
    "class_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Visualising random sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Image Shape: {image.shape}\")\n",
    "plt.imshow(image.squeeze())\n",
    "plt.title(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gray scale\n",
    "plt.imshow(image.squeeze(),cmap=\"gray\")\n",
    "plt.title(classnames[label])\n",
    "plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualising random images\n",
    "tc.manual_seed(42)\n",
    "fig = plt.figure(figsize=(9,9))\n",
    "rows,cols = 4,4\n",
    "for i in range(1,rows*cols+1):\n",
    "  random_idx = tc.randint(0,len(train_data),size=[1]).item()\n",
    "  # print(random_idx)\n",
    "  img,lab = train_data[random_idx]\n",
    "  fig.add_subplot(rows,cols,i)\n",
    "  plt.imshow(img.squeeze(),cmap=\"gray\")\n",
    "  plt.title(classnames[lab])\n",
    "  plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Preparing Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# batch size hyper parameter\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# turn dataset into iterable\n",
    "train_dataloader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "train_dataloader,test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"DataLoaders: {train_dataloader,test_dataloader}\")\n",
    "print(f\"Length of train data loader: {len(train_dataloader)} batches of {BATCH_SIZE}...\")\n",
    "print(f\"Length of test data loader: {len(test_dataloader)} batches of {BATCH_SIZE}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking training data loader\n",
    "train_features_batch, train_label_batch = next(iter(train_dataloader))\n",
    "train_features_batch.shape,train_label_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a sample\n",
    "tc.manual_seed(42)\n",
    "random_idx = tc.randint(0,len(train_features_batch),size=[1]).item()\n",
    "img, lab = train_features_batch[random_idx],train_label_batch[random_idx]\n",
    "plt.imshow(img.squeeze(),cmap=\"gray\")\n",
    "plt.title(classnames[lab])\n",
    "plt.axis(False)\n",
    "print(f\"Image size: {img.shape}\")\n",
    "print(f\"Label: {lab}, Label size: {lab.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Creating a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a baseline model\n",
    "flatten_model = nn.Flatten()\n",
    "\n",
    "# get a single sample\n",
    "x = train_features_batch[0]\n",
    "x.shape\n",
    "# flatten x\n",
    "output = flatten_model(x)\n",
    "print(f\"Shape before flattening: {x.shape}\\nShape after flattening: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTModelV0(nn.Module):\n",
    "  def __init__(self,input_shape:int,hidden_unit:int,output_shpe:int):\n",
    "    super().__init__()\n",
    "    self.layer_stack = nn.Sequential(\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(in_features=input_shape,out_features=hidden_unit),\n",
    "      nn.Linear(in_features=hidden_unit,out_features=output_shpe)\n",
    "    )\n",
    "    \n",
    "  def forward(self,x):\n",
    "    return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.manual_seed(42)\n",
    "model0 = FashionMNISTModelV0(input_shape=784,hidden_unit=10,output_shpe=len(classnames))\n",
    "\n",
    "model0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 Setup loss function and optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import accuracy functions\n",
    "from helper import accuracy_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimiser = tc.optim.SGD(params=model0.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up timer function\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "\n",
    "def print_train_time(start: float, end: float, devive: tc.device = None):\n",
    "    \"\"\"Prints difference between start time and end time\"\"\"\n",
    "    total_time = end - start\n",
    "    print(f\"Train time on {devive}: {total_time:.3f} seconds\")\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 Training loop for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy (a classification metric)\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    \"\"\"Calculates accuracy between truth labels and predictions.\n",
    "\n",
    "    Args:\n",
    "        y_true (torch.Tensor): Truth labels for predictions.\n",
    "        y_pred (torch.Tensor): Predictions to be compared to predictions.\n",
    "\n",
    "    Returns:\n",
    "        [torch.float]: Accuracy value between y_true and y_pred, e.g. 78.45\n",
    "    \"\"\"\n",
    "    correct = tc.eq(y_true, y_pred).sum().item()\n",
    "    acc = (correct / len(y_pred)) * 100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# set the seed\n",
    "tc.manual_seed(42)\n",
    "start_time = timer()\n",
    "\n",
    "# set epochs\n",
    "epochs = 3\n",
    "\n",
    "# create training and test loop\n",
    "for epoch in tqdm(range(epochs)):\n",
    "  print(f\"Epoch: {epoch}\\n-----\")\n",
    "  # training\n",
    "  train_loss = 0\n",
    "  # add a loop to loop through the training batches\n",
    "  for batch,(X,y) in enumerate(train_dataloader):\n",
    "    model0.train()\n",
    "    # 1. forward pass\n",
    "    y_pred = model0(X)\n",
    "    # 2. calculate the loss\n",
    "    loss = loss_fn(y_pred,y)\n",
    "    train_loss +=loss\n",
    "    # 3. optimise the zero grad\n",
    "    optimiser.zero_grad()\n",
    "    # 4. loss backward\n",
    "    loss.backward()\n",
    "    # optimise the step\n",
    "    optimiser.step()\n",
    "  \n",
    "    # print what is happening\n",
    "    if batch % 400 == 0:\n",
    "      print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
    "\n",
    "  # Divide total train loss by the lenght of the train dataloader\n",
    "  train_loss /= len(train_dataloader)\n",
    "  \n",
    "  ### Testing\n",
    "  test_loss,test_acc = 0,0\n",
    "  model0.eval()\n",
    "  with tc.inference_mode():\n",
    "    for X_test,y_test in test_dataloader:\n",
    "      # 1. forward pass\n",
    "      test_pred = model0(X_test)\n",
    "      # 2. calculate the loss\n",
    "      test_loss += loss_fn(test_pred,y_test)\n",
    "      # 3. calculate accuracy\n",
    "      test_acc += accuracy_fn(y_true=y_test,y_pred=test_pred.argmax(dim=1))\n",
    "    # calculate the test loss avg per batch\n",
    "    test_loss /= len(test_dataloader)\n",
    "    # calculate the test acc avg per batch\n",
    "    test_acc /= len(test_dataloader)\n",
    "    \n",
    "  # print what is happening\n",
    "  print(f\"\\nTrain loss: {train_loss:.4f} | Test loss: {test_loss:.4f}, Test acc: {test_acc:.3f}\")\n",
    "  \n",
    "# Calculate the training time\n",
    "end_time = timer()\n",
    "total_time0 = print_train_time(start=start_time,end=end_time,devive=str(next(model0.parameters()).device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making some predictions\n",
    "tc.manual_seed(42)\n",
    "def eval_model(model:tc.nn.Module,data_loader:tc.utils.data.DataLoader,loss_fn:tc.nn.Module,accuracy_fn):\n",
    "  \"\"\"Return a disctionary containing the results of model predicting on data loader.\"\"\"\n",
    "  \n",
    "  loss, acc = 0,0\n",
    "  model.eval()\n",
    "  with tc.inference_mode():\n",
    "    for X,y in data_loader:\n",
    "      # make predictions\n",
    "      y_pred = model(X)\n",
    "      \n",
    "      # accumulate the loss and acc values per patch\n",
    "      loss += loss_fn(y_pred,y)\n",
    "      acc += accuracy_fn(y_true=y,y_pred=y_pred.argmax(dim=1))\n",
    "    # scalle the loss and acc\n",
    "    loss /= len(data_loader)\n",
    "    acc /= len(data_loader)\n",
    "    \n",
    "  return {\"Model name\": model.__class__.__name__,\"Model Loss\": loss.item(),\"Model acc\": acc}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate model 0 result on our dataset\n",
    "model0_results = eval_model(model=model0,data_loader=test_dataloader,loss_fn=loss_fn,accuracy_fn=accuracy_fn)\n",
    "\n",
    "model0_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Improving through experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.1 Building a better model with non linearlity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTModelV1(nn.Module):\n",
    "  def __init__(self,input_shape:int,hidden_units:int,output_shape:int):\n",
    "    super().__init__()\n",
    "    self.layer_stack = nn.Sequential(\n",
    "      nn.Flatten(),\n",
    "      nn.Linear(in_features=input_shape,out_features=hidden_units),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(in_features=hidden_units,out_features=output_shape),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "  \n",
    "  def forward(self,x:tc.Tensor):\n",
    "    return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an instanc of model 1\n",
    "tc.manual_seed(42)\n",
    "model1 = FashionMNISTModelV1(input_shape=784,hidden_units=10,output_shape=len(classnames))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.1.1 Setting up loss function and optimizer and a training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn1 = nn.CrossEntropyLoss()\n",
    "optimiser1 = tc.optim.SGD(params=model1.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# set the seed\n",
    "tc.manual_seed(42)\n",
    "start_time = timer()\n",
    "\n",
    "# set epochs\n",
    "epochs = 3\n",
    "\n",
    "# create training and test loop\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n-----\")\n",
    "    # training\n",
    "    train_loss = 0\n",
    "    # add a loop to loop through the training batches\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        model1.train()\n",
    "        # 1. forward pass\n",
    "        y_pred = model0(X)\n",
    "        # 2. calculate the loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        # 3. optimise the zero grad\n",
    "        optimiser1.zero_grad()\n",
    "        # 4. loss backward\n",
    "        loss.backward()\n",
    "        # optimise the step\n",
    "        optimiser1.step()\n",
    "\n",
    "        # print what is happening\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
    "\n",
    "    # Divide total train loss by the lenght of the train dataloader\n",
    "    train_loss /= len(train_dataloader)\n",
    "\n",
    "    ### Testing\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model1.eval()\n",
    "    with tc.inference_mode():\n",
    "        for X_test, y_test in test_dataloader:\n",
    "            # 1. forward pass\n",
    "            test_pred = model1(X_test)\n",
    "            # 2. calculate the loss\n",
    "            test_loss += loss_fn(test_pred, y_test)\n",
    "            # 3. calculate accuracy\n",
    "            test_acc += accuracy_fn(y_true=y_test, y_pred=test_pred.argmax(dim=1))\n",
    "        # calculate the test loss avg per batch\n",
    "        test_loss /= len(test_dataloader)\n",
    "        # calculate the test acc avg per batch\n",
    "        test_acc /= len(test_dataloader)\n",
    "\n",
    "    # print what is happening\n",
    "    print(\n",
    "        f\"\\nTrain loss: {train_loss:.4f} | Test loss: {test_loss:.4f}, Test acc: {test_acc:.3f}\"\n",
    "    )\n",
    "\n",
    "# Calculate the training time\n",
    "end_time = timer()\n",
    "total_time1 = print_train_time(\n",
    "    start=start_time, end=end_time, devive=str(next(model1.parameters()).device)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
