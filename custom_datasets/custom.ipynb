{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Pytorch Custom Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch as tc\n",
    "from torch import nn\n",
    "# import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Getting our datasets and becoming one with Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def walk_through_dir(dir_path):\n",
    "  \"\"\"walks through dir path returning its content\"\"\"\n",
    "  for dirpath,dirnames,filenames in os.walk(dir_path):\n",
    "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in {dirpath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_through_dir(dir_path=\"DATA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "data_path = Path(\"DATA/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up our train and test path\n",
    "train_dir = data_path / \"train\"\n",
    "test_dir = data_path / \"test\"\n",
    "train_dir,test_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 Visuallising our image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "# set seed\n",
    "tc.manual_seed(42)\n",
    "\n",
    "# 1. get all the image path\n",
    "image_path_list = list(data_path.glob(\"*/*/*.jpg\"))\n",
    "# image_path_list\n",
    "\n",
    "# 2. Plot random image\n",
    "random_image_path = random.choice(image_path_list)\n",
    "print(random_image_path)\n",
    "\n",
    "# 3. get the image class\n",
    "image_class = random_image_path.parent.stem\n",
    "print(image_class)\n",
    "\n",
    "# 4. open the image\n",
    "img = Image.open(random_image_path)\n",
    "\n",
    "# 5. print meta data\n",
    "print(f\"Random image path: {random_image_path}\")\n",
    "print(f\"Image class: {image_class}\")\n",
    "print(f\"Image Height: {img.height}\")\n",
    "print(f\"Image width: {img.width}\")\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)\n",
    "plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_as_array = np.asarray(img)\n",
    "img_as_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Transforming our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 Transform data with `torchvision.transform`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "  # resize the image\n",
    "  transforms.Resize(size=(64,64)),\n",
    "  # flip the image\n",
    "  transforms.RandomHorizontalFlip(p=0.5),\n",
    "  # Turn image into a torch tensor\n",
    "  ToTensor()\n",
    "])\n",
    "\n",
    "data_transform(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_transformed_images(images_paths,transform,n=3,seed=None):\n",
    "  \"\"\"\n",
    "    Selects random images from a path of images and loads/transforms them then plots the original vs the transformed version\n",
    "  \"\"\"\n",
    "  if seed:\n",
    "    random.seed(seed)\n",
    "    random_image_paths = random.sample(images_paths,k=n)\n",
    "    for image_path in random_image_paths:\n",
    "      with Image.open(image_path) as f:\n",
    "        fig,ax = plt.subplots(nrows=1,ncols=2)\n",
    "        ax[0].imshow(f)\n",
    "        ax[0].set_title(f\"Origin\\nSize: {f.size}\")\n",
    "        ax[0].axis(False)\n",
    "        \n",
    "        # transform and plot target image\n",
    "        transformed_image = transform(f).permute(1,2,0) # not we will need to change the sahpe for the transform\n",
    "        ax[1].imshow(transformed_image)\n",
    "        ax[1].set_title(f\"Transformed\\nShape: {transformed_image.shape}\")\n",
    "        ax[1].axis(False)\n",
    "        \n",
    "        fig.suptitle(f\"Class: {image_path.parent.stem}\", fontsize=16) \n",
    "\n",
    "plot_transformed_images(image_path_list,transform=data_transform,seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Option1 Loading image data using ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use image folder to create datasets\n",
    "train_data = datasets.ImageFolder(root=train_dir,transform=data_transform,target_transform=None)\n",
    "test_data = datasets.ImageFolder(root=test_dir,transform=data_transform,target_transform=None)\n",
    "\n",
    "train_data,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting classnames\n",
    "train_classnames = train_data.classes\n",
    "train_classnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index on the train data datasets\n",
    "img,label =  train_data[1][0], train_data[1][1]\n",
    "# img,label\n",
    "print(f\"Image Tensor:\\n{img}\") \n",
    "print(f\"Image Shape:\\n{img.dtype}\") \n",
    "print(f\"Image Datatype:\\n{img.dtype}\")\n",
    "print(f\"Image Label:\\n{train_classnames[label]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange the order of dimension\n",
    "img_permute = img.permute(1,2,0)\n",
    "\n",
    "# print out different shapes\n",
    "print(f\"Original shape: {img.shape} -> [color_channels, height, width]\")\n",
    "print(f\"Image Permute shape: {img_permute.shape} -> [height, width, color_channels]\")\n",
    "\n",
    "# plot the image\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.imshow(img_permute)\n",
    "plt.axis(False)\n",
    "plt.title(train_classnames[label],fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 Turn loaded images into Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_data, batch_size=BATCH_SIZE, num_workers=os.cpu_count(), shuffle=True\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_data, batch_size=BATCH_SIZE, num_workers=os.cpu_count(), shuffle=True\n",
    ")\n",
    "\n",
    "len(train_dataloader),len(test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Option2 Loading Image Data with a custom `Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple,Dict,List\n",
    "train_data.classes, train_data.class_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.1 Creating a helper function to get classnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def \n",
    "# setup target directory\n",
    "target_directory = train_dir\n",
    "print(f\"Target dir: {target_directory}\")\n",
    "\n",
    "# get the class names from the target directory\n",
    "class_names_found = sorted([entry.name for entry in list(os.scandir(target_directory))])\n",
    "class_names_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_classes(directory:str) -> Tuple[List[str],Dict[str,int]]:\n",
    "  \"\"\"Finds the class folder names in a target directory.\"\"\"\n",
    "  # 1. Get the class names by scanning the target directory\n",
    "  classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
    "  \n",
    "  # 2. raise an error if class names nt found\n",
    "  if not classes:\n",
    "    raise FileNotFoundError(f\"Couldn't find any classes in {directory}...please check the file structure\")\n",
    "  \n",
    "  # 3. create a dictionary of index labels\n",
    "  classes_to_idx = {class_name: i for i, class_name in enumerate(classes)}\n",
    "  return classes, classes_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_classes(target_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
