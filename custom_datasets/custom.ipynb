{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Pytorch Custom Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch as tc\n",
    "from torch import nn\n",
    "# import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Getting our datasets and becoming one with Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def walk_through_dir(dir_path):\n",
    "  \"\"\"walks through dir path returning its content\"\"\"\n",
    "  for dirpath,dirnames,filenames in os.walk(dir_path):\n",
    "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in {dirpath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_through_dir(dir_path=\"DATA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "data_path = Path(\"DATA/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up our train and test path\n",
    "train_dir = data_path / \"train\"\n",
    "test_dir = data_path / \"test\"\n",
    "train_dir,test_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 Visuallising our image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "# set seed\n",
    "tc.manual_seed(42)\n",
    "\n",
    "# 1. get all the image path\n",
    "image_path_list = list(data_path.glob(\"*/*/*.jpg\"))\n",
    "# image_path_list\n",
    "\n",
    "# 2. Plot random image\n",
    "random_image_path = random.choice(image_path_list)\n",
    "print(random_image_path)\n",
    "\n",
    "# 3. get the image class\n",
    "image_class = random_image_path.parent.stem\n",
    "print(image_class)\n",
    "\n",
    "# 4. open the image\n",
    "img = Image.open(random_image_path)\n",
    "\n",
    "# 5. print meta data\n",
    "print(f\"Random image path: {random_image_path}\")\n",
    "print(f\"Image class: {image_class}\")\n",
    "print(f\"Image Height: {img.height}\")\n",
    "print(f\"Image width: {img.width}\")\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)\n",
    "plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_as_array = np.asarray(img)\n",
    "img_as_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Transforming our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 Transform data with `torchvision.transform`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "  # resize the image\n",
    "  transforms.Resize(size=(64,64)),\n",
    "  # flip the image\n",
    "  transforms.RandomHorizontalFlip(p=0.5),\n",
    "  # Turn image into a torch tensor\n",
    "  ToTensor()\n",
    "])\n",
    "\n",
    "data_transform(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_transformed_images(images_paths,transform,n=3,seed=None):\n",
    "  \"\"\"\n",
    "    Selects random images from a path of images and loads/transforms them then plots the original vs the transformed version\n",
    "  \"\"\"\n",
    "  if seed:\n",
    "    random.seed(seed)\n",
    "    random_image_paths = random.sample(images_paths,k=n)\n",
    "    for image_path in random_image_paths:\n",
    "      with Image.open(image_path) as f:\n",
    "        fig,ax = plt.subplots(nrows=1,ncols=2)\n",
    "        ax[0].imshow(f)\n",
    "        ax[0].set_title(f\"Origin\\nSize: {f.size}\")\n",
    "        ax[0].axis(False)\n",
    "        \n",
    "        # transform and plot target image\n",
    "        transformed_image = transform(f).permute(1,2,0) # not we will need to change the sahpe for the transform\n",
    "        ax[1].imshow(transformed_image)\n",
    "        ax[1].set_title(f\"Transformed\\nShape: {transformed_image.shape}\")\n",
    "        ax[1].axis(False)\n",
    "        \n",
    "        fig.suptitle(f\"Class: {image_path.parent.stem}\", fontsize=16) \n",
    "\n",
    "plot_transformed_images(image_path_list,transform=data_transform,seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
