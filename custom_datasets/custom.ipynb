{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Pytorch Custom Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch as tc\n",
    "from torch import nn\n",
    "# import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Getting our datasets and becoming one with Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def walk_through_dir(dir_path):\n",
    "  \"\"\"walks through dir path returning its content\"\"\"\n",
    "  for dirpath,dirnames,filenames in os.walk(dir_path):\n",
    "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in {dirpath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_through_dir(dir_path=\"DATA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "data_path = Path(\"DATA/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up our train and test path\n",
    "train_dir = data_path / \"train\"\n",
    "test_dir = data_path / \"test\"\n",
    "train_dir,test_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 Visuallising our image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "# set seed\n",
    "tc.manual_seed(42)\n",
    "\n",
    "# 1. get all the image path\n",
    "image_path_list = list(data_path.glob(\"*/*/*.jpg\"))\n",
    "# image_path_list\n",
    "\n",
    "# 2. Plot random image\n",
    "random_image_path = random.choice(image_path_list)\n",
    "print(random_image_path)\n",
    "\n",
    "# 3. get the image class\n",
    "image_class = random_image_path.parent.stem\n",
    "print(image_class)\n",
    "\n",
    "# 4. open the image\n",
    "img = Image.open(random_image_path)\n",
    "\n",
    "# 5. print meta data\n",
    "print(f\"Random image path: {random_image_path}\")\n",
    "print(f\"Image class: {image_class}\")\n",
    "print(f\"Image Height: {img.height}\")\n",
    "print(f\"Image width: {img.width}\")\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)\n",
    "plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_as_array = np.asarray(img)\n",
    "img_as_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Transforming our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 Transform data with `torchvision.transform`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "  # resize the image\n",
    "  transforms.Resize(size=(64,64)),\n",
    "  # flip the image\n",
    "  transforms.RandomHorizontalFlip(p=0.5),\n",
    "  # Turn image into a torch tensor\n",
    "  ToTensor()\n",
    "])\n",
    "\n",
    "data_transform(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_transformed_images(images_paths,transform,n=3,seed=None):\n",
    "  \"\"\"\n",
    "    Selects random images from a path of images and loads/transforms them then plots the original vs the transformed version\n",
    "  \"\"\"\n",
    "  if seed:\n",
    "    random.seed(seed)\n",
    "    random_image_paths = random.sample(images_paths,k=n)\n",
    "    for image_path in random_image_paths:\n",
    "      with Image.open(image_path) as f:\n",
    "        fig,ax = plt.subplots(nrows=1,ncols=2)\n",
    "        ax[0].imshow(f)\n",
    "        ax[0].set_title(f\"Origin\\nSize: {f.size}\")\n",
    "        ax[0].axis(False)\n",
    "        \n",
    "        # transform and plot target image\n",
    "        transformed_image = transform(f).permute(1,2,0) # not we will need to change the sahpe for the transform\n",
    "        ax[1].imshow(transformed_image)\n",
    "        ax[1].set_title(f\"Transformed\\nShape: {transformed_image.shape}\")\n",
    "        ax[1].axis(False)\n",
    "        \n",
    "        fig.suptitle(f\"Class: {image_path.parent.stem}\", fontsize=16) \n",
    "\n",
    "plot_transformed_images(image_path_list,transform=data_transform,seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Option1 Loading image data using ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use image folder to create datasets\n",
    "train_data = datasets.ImageFolder(root=train_dir,transform=data_transform,target_transform=None)\n",
    "test_data = datasets.ImageFolder(root=test_dir,transform=data_transform,target_transform=None)\n",
    "\n",
    "train_data,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting classnames\n",
    "train_classnames = train_data.classes\n",
    "train_classnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index on the train data datasets\n",
    "img,label =  train_data[1][0], train_data[1][1]\n",
    "# img,label\n",
    "print(f\"Image Tensor:\\n{img}\") \n",
    "print(f\"Image Shape:\\n{img.dtype}\") \n",
    "print(f\"Image Datatype:\\n{img.dtype}\")\n",
    "print(f\"Image Label:\\n{train_classnames[label]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange the order of dimension\n",
    "img_permute = img.permute(1,2,0)\n",
    "\n",
    "# print out different shapes\n",
    "print(f\"Original shape: {img.shape} -> [color_channels, height, width]\")\n",
    "print(f\"Image Permute shape: {img_permute.shape} -> [height, width, color_channels]\")\n",
    "\n",
    "# plot the image\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.imshow(img_permute)\n",
    "plt.axis(False)\n",
    "plt.title(train_classnames[label],fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 Turn loaded images into Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_data, batch_size=BATCH_SIZE, num_workers=os.cpu_count(), shuffle=True\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_data, batch_size=BATCH_SIZE, num_workers=os.cpu_count(), shuffle=True\n",
    ")\n",
    "\n",
    "len(train_dataloader),len(test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Option2 Loading Image Data with a custom `Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple,Dict,List\n",
    "train_data.classes, train_data.class_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.1 Creating a helper function to get classnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def \n",
    "# setup target directory\n",
    "target_directory = train_dir\n",
    "print(f\"Target dir: {target_directory}\")\n",
    "\n",
    "# get the class names from the target directory\n",
    "class_names_found = sorted([entry.name for entry in list(os.scandir(target_directory))])\n",
    "class_names_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_classes(directory:str) -> Tuple[List[str],Dict[str,int]]:\n",
    "  \"\"\"Finds the class folder names in a target directory.\"\"\"\n",
    "  # 1. Get the class names by scanning the target directory\n",
    "  classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
    "  \n",
    "  # 2. raise an error if class names nt found\n",
    "  if not classes:\n",
    "    raise FileNotFoundError(f\"Couldn't find any classes in {directory}...please check the file structure\")\n",
    "  \n",
    "  # 3. create a dictionary of index labels\n",
    "  classes_to_idx = {class_name: i for i, class_name in enumerate(classes)}\n",
    "  return classes, classes_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_classes(target_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.2 Create a custom `Dataset` to replicate `ImageFolder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "# 1. subclass\n",
    "class ImageFolderCustom(Dataset):\n",
    "  # 2. Inititalise the custom dataset\n",
    "  def __init__(self,targ_dir:str,transform=None):\n",
    "    # 3. create class attributes\n",
    "    # get all the input image paths\n",
    "    self.paths = list(Path(targ_dir).glob(\"*/*.jpg\"))\n",
    "    # setup transforms\n",
    "    self.transform = transform\n",
    "    # create classes and class_to_idx\n",
    "    self.classes,self.class_to_idx = find_classes(targ_dir)\n",
    "    \n",
    "  # 4. create a function to load images\n",
    "  def load_image(self,index:int) -> Image.Image:\n",
    "    \"\"\"Opens an image file paths and returns it\"\"\"\n",
    "    image_path = self.paths[index]\n",
    "    return Image.open(image_path)\n",
    "  \n",
    "  # 5. overwrite __len__()\n",
    "  def __len__(self) -> int:\n",
    "    \"\"\"Return total number of samples\"\"\"\n",
    "    return len(self.paths)\n",
    "  \n",
    "  # 6. overwrite __getitem__\n",
    "  def __getitem__(self,index:int) -> Tuple[tc.Tensor,int]:\n",
    "    \"\"\"Returns one sample of data and label (X,y)\"\"\"\n",
    "    img = self.load_image(index)\n",
    "    class_name = self.paths[index].parent.name \n",
    "    class_idx = self.class_to_idx[class_name]\n",
    "    \n",
    "    # Transform if necassary\n",
    "    \n",
    "    if self.transform:\n",
    "      return self.transform(img) ,class_idx\n",
    "    else:\n",
    "      return img,class_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "train_transforms = transforms.Compose([\n",
    "  transforms.Resize(size=(64,64)),\n",
    "  transforms.RandomHorizontalFlip(p=0.5),\n",
    "  transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "  transforms.Resize(size=(64,64)),\n",
    "  transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test out ImageCustomFolder\n",
    "train_data_custom = ImageFolderCustom(targ_dir=train_dir,transform=train_transforms)\n",
    "test_data_custom = ImageFolderCustom(targ_dir=train_dir,transform=test_transforms)\n",
    "train_data_custom,test_data_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for equality between original ImageFolder Dataset and ImageFolderCustomDataset\n",
    "print(train_data_custom.classes == train_data.classes)\n",
    "print(test_data_custom.classes == test_data.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.3 Create a custom function to display random images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. create a function to take in a dataset\n",
    "def display_random_images(dataset:tc.utils.data.Dataset,classes:List[str] = None,n:int = 10,display_shape:bool = True,seed:int = None):\n",
    "  # 2. Adjust display\n",
    "  if n > 10:\n",
    "    n = 10\n",
    "    display_shape = False\n",
    "    print(f\"For display purposes, n shouldn't be larger than 10, setting to 10 and removing shape display.\")\n",
    "    \n",
    "  # 3. set the random seed\n",
    "  if seed:\n",
    "    random.seed(seed)\n",
    "    \n",
    "  # 4. get rnadom indexes\n",
    "  random_samples_idx = random.sample(range(len(dataset)),k=n)\n",
    "  \n",
    "  # 5. setup the plot\n",
    "  plt.figure(figsize=(16,10))  \n",
    "  \n",
    "  # 6. loop through random sample images\n",
    "  for i,targ_smaple in enumerate(random_samples_idx):\n",
    "    targ_image,targ_label = dataset[targ_smaple][0],dataset[targ_smaple][1]\n",
    "    \n",
    "    # 7. Adjust tensor dimensions for plotting\n",
    "    targ_image_adjust = targ_image.permute(1,2,0)\n",
    "    \n",
    "    # plot adjusted samples\n",
    "    plt.subplot(1,n,i+1)\n",
    "    plt.imshow(targ_image_adjust)\n",
    "    plt.axis(False)\n",
    "    \n",
    "    if classes:\n",
    "      title = f\"classes: {classes[targ_label]}\"\n",
    "      if display_shape:\n",
    "        title = title + f\"\\nShape: {targ_image_adjust.shape}\"\n",
    "        \n",
    "    plt.title(title)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "display_random_images(train_data,n=4,classes=train_classnames,seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_random_images(train_data_custom, n=4, classes=train_classnames, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Turn custom loaded images into DataLoader's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_dataloader_custom = DataLoader(\n",
    "    dataset=train_data_custom, batch_size=BATCH_SIZE, num_workers=0, shuffle=True\n",
    ")\n",
    "test_dataloader_custom = DataLoader(\n",
    "    dataset=test_data_custom,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=0,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "train_dataloader_custom, test_dataloader_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get imaeg and label\n",
    "img_custom, lable_custom = next(iter(train_dataloader_custom))\n",
    "\n",
    "# Print out the shapes\n",
    "img_custom.shape, lable_custom.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Other forms of transforms (data augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "  transforms.Resize(size=(224,224)),\n",
    "  transforms.TrivialAugmentWide(num_magnitude_bins=5),\n",
    "  transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "  transforms.Resize(size=(224,224)),\n",
    "  transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot random transformed images\n",
    "plot_transformed_images(images_paths=image_path_list,transform=train_transform,n=3,seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7 Model 0: TinyVGG without data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7.1 Creating transforms and loading data for Model 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create simple transform\n",
    "simple_transform = transforms.Compose([\n",
    "  transforms.Resize(size=(64,64)),\n",
    "  transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. load and transform data\n",
    "train_data_simple = datasets.ImageFolder(root=train_dir, transform=simple_transform)\n",
    "test_data_simple = datasets.ImageFolder(root=test_dir, transform=simple_transform)\n",
    "\n",
    "# 2. Train dataset into data loader\n",
    "train_dataloader_simple = DataLoader(\n",
    "    dataset=train_data_simple,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=os.cpu_count(),\n",
    ")\n",
    "test_dataloader_simple = DataLoader(\n",
    "    dataset=test_data_simple, batch_size=BATCH_SIZE, num_workers=os.cpu_count()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7.2 Create TinyVGG class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyVGG(nn.Module):\n",
    "    \"\"\"Model architecture copying TinyVGG from CNN Explainer\"\"\"\n",
    "\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=input_shape,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=hidden_units,\n",
    "                out_channels=hidden_units,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(), nn.Linear(in_features=hidden_units*16*16, out_features=output_shape)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "      x = self.conv_block_1(x)\n",
    "      print(x.shape)\n",
    "      x = self.conv_block_2(x)\n",
    "      print(x.shape)\n",
    "      x = self.classifier(x)\n",
    "      print(x.shape)\n",
    "      return x\n",
    "      # return self.classifier(self.conv_block_2(self.conv_block_1(x))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "tc.manual_seed(42)\n",
    "model0 = TinyVGG(input_shape=3,hidden_units=10,output_shape=len(train_classnames))\n",
    "model0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7.3 Trying a forward pass on a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a single image batch\n",
    "image_batch, label_batch = next(iter(train_dataloader_simple))\n",
    "image_batch.shape,label_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a forward pass\n",
    "model0(image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
